{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bcdc8734-ecd1-4dac-aeb5-c70f8d61f355",
   "metadata": {},
   "source": [
    "<hr style=\"border-top:5px solid Gold; margin-top: 2px; margin-bottom: 0px\">\n",
    "<hr style=\"border-top:5px solid Silver; margin-top: 0px; margin-bottom: 0px\">\n",
    "<hr style=\"border-top:5px solid #DC9233; margin-top: 0px; margin-bottom: 0px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21658513-8cfe-414b-935d-615850234dfe",
   "metadata": {},
   "source": [
    "# Medals at the Olympics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6eda6c-45c0-45be-b507-180c595accf9",
   "metadata": {},
   "source": [
    "<hr style=\"border-top:5px solid Gold; margin-top: 2px; margin-bottom: 0px\">\n",
    "<hr style=\"border-top:5px solid Silver; margin-top: 0px; margin-bottom: 0px\">\n",
    "<hr style=\"border-top:5px solid #DC9233; margin-top: 0px; margin-bottom: 0px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee25bc7a-e08f-4f65-9646-16bbb2534a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import pandas as pd\n",
    "\n",
    "# Visulation Imports\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# import splitting and imputing functions\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Modeling imports\n",
    "from sklearn.linear_model import LinearRegression, LassoLars, TweedieRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, explained_variance_score\n",
    "from sklearn.feature_selection import f_regression \n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.feature_selection import SelectKBest, f_regression, RFE\n",
    "import sklearn.preprocessing\n",
    "import statsmodels.api as sm\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# turn off pink boxes\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Custom Imports\n",
    "import wrangle\n",
    "import explore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35e4fd5-ed8c-4966-9ff6-692010576339",
   "metadata": {},
   "source": [
    "## Project Goal\n",
    "- Create a classification model to predict if an olympic athlete will medal or not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb13fd19-2f02-4bc7-8d0e-139a2c46a793",
   "metadata": {},
   "source": [
    "<hr style=\"border-top:5px solid Gold; margin-top: 2px; margin-bottom: 0px\">\n",
    "<hr style=\"border-top:5px solid Silver; margin-top: 0px; margin-bottom: 0px\">\n",
    "<hr style=\"border-top:5px solid #DC9233; margin-top: 0px; margin-bottom: 0px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23bb0036-375e-4f16-8516-a523c518c0b2",
   "metadata": {},
   "source": [
    "# Acquire and Prepare"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52910512-1379-4791-aaf5-f51fe4ad2c0b",
   "metadata": {},
   "source": [
    "<hr style=\"border-top:5px solid Gold; margin-top: 2px; margin-bottom: 0px\">\n",
    "<hr style=\"border-top:5px solid Silver; margin-top: 0px; margin-bottom: 0px\">\n",
    "<hr style=\"border-top:5px solid #DC9233; margin-top: 0px; margin-bottom: 0px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701abc5e-9e8e-4925-9717-676f92a76bae",
   "metadata": {},
   "source": [
    "#### This function reads 2 csv's and assigns them into a dataframe. It then feature engineers 5 new columns, those columns are Medal, Sex_Male, medalist, BMI, and AgeBins. From there it splits the data and imputes the null values for Age, drops data prior to the year 1961, and drops the remaining nulls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e855331b-1b82-4efb-8b13-4cbc36d13d5d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [216892, 271116]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df, df1, train, validate, test \u001b[38;5;241m=\u001b[39m \u001b[43mwrangle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrangle_df\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/data-science-projects/olympic_dataset/wrangle.py:62\u001b[0m, in \u001b[0;36mwrangle_df\u001b[0;34m()\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# train/validate/test split\u001b[39;00m\n\u001b[1;32m     61\u001b[0m train_validate, test \u001b[38;5;241m=\u001b[39m train_test_split(df, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m123\u001b[39m, stratify\u001b[38;5;241m=\u001b[39mdf\u001b[38;5;241m.\u001b[39mmedalist)\n\u001b[0;32m---> 62\u001b[0m train, validate \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_validate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m.3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m123\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstratify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmedalist\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m imputer \u001b[38;5;241m=\u001b[39m SimpleImputer(strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     64\u001b[0m imputer \u001b[38;5;241m=\u001b[39m imputer\u001b[38;5;241m.\u001b[39mfit(train[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAge\u001b[39m\u001b[38;5;124m'\u001b[39m]])\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:2441\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2437\u001b[0m         CVClass \u001b[38;5;241m=\u001b[39m ShuffleSplit\n\u001b[1;32m   2439\u001b[0m     cv \u001b[38;5;241m=\u001b[39m CVClass(test_size\u001b[38;5;241m=\u001b[39mn_test, train_size\u001b[38;5;241m=\u001b[39mn_train, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m-> 2441\u001b[0m     train, test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marrays\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstratify\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2443\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\n\u001b[1;32m   2444\u001b[0m     chain\u001b[38;5;241m.\u001b[39mfrom_iterable(\n\u001b[1;32m   2445\u001b[0m         (_safe_indexing(a, train), _safe_indexing(a, test)) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m arrays\n\u001b[1;32m   2446\u001b[0m     )\n\u001b[1;32m   2447\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:1599\u001b[0m, in \u001b[0;36mBaseShuffleSplit.split\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m   1569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msplit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, groups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1570\u001b[0m     \u001b[38;5;124;03m\"\"\"Generate indices to split data into training and test set.\u001b[39;00m\n\u001b[1;32m   1571\u001b[0m \n\u001b[1;32m   1572\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1597\u001b[0m \u001b[38;5;124;03m    to an integer.\u001b[39;00m\n\u001b[1;32m   1598\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1599\u001b[0m     X, y, groups \u001b[38;5;241m=\u001b[39m \u001b[43mindexable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1600\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter_indices(X, y, groups):\n\u001b[1;32m   1601\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m train, test\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:378\u001b[0m, in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;124;03m\"\"\"Make arrays indexable for cross-validation.\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \n\u001b[1;32m    361\u001b[0m \u001b[38;5;124;03mChecks consistent length, passes through None, and ensures that everything\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;124;03m    sparse matrix, or dataframe) or `None`.\u001b[39;00m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    377\u001b[0m result \u001b[38;5;241m=\u001b[39m [_make_indexable(X) \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m iterables]\n\u001b[0;32m--> 378\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:332\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    330\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 332\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    333\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    334\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[1;32m    335\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [216892, 271116]"
     ]
    }
   ],
   "source": [
    "df, df1, train, validate, test = wrangle.wrangle_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fff74f-497d-4dda-9bed-54a718df577b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c21dea-f2d7-4d8e-9561-d9d17b4ec5ea",
   "metadata": {},
   "source": [
    "## Acquire and Prepare Takeaways"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0547936-4adc-41ba-81f0-abdf0d41e7f4",
   "metadata": {},
   "source": [
    "- 5 columns were feature engineered.\n",
    "- Nulls were handled by imputing with mean, dropping old data, and dropping the remaining nulls.\n",
    "- Our dataframe was left with 271,116 rows and 19 columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588fb6df-7b0f-40cb-8f21-b70371e19216",
   "metadata": {},
   "source": [
    "<hr style=\"border-top:5px solid Gold; margin-top: 2px; margin-bottom: 0px\">\n",
    "<hr style=\"border-top:5px solid Silver; margin-top: 0px; margin-bottom: 0px\">\n",
    "<hr style=\"border-top:5px solid #DC9233; margin-top: 0px; margin-bottom: 0px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bbb7be-5d8f-4230-aa7e-7975df4d7d50",
   "metadata": {},
   "source": [
    "# Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2086f886-1fbb-4e4b-9d29-19901230da71",
   "metadata": {},
   "source": [
    "<hr style=\"border-top:5px solid Gold; margin-top: 2px; margin-bottom: 0px\">\n",
    "<hr style=\"border-top:5px solid Silver; margin-top: 0px; margin-bottom: 0px\">\n",
    "<hr style=\"border-top:5px solid #DC9233; margin-top: 0px; margin-bottom: 0px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f53ea1-649f-4f56-b3b2-ccaab05b3414",
   "metadata": {},
   "source": [
    "## Lets look at the correlations in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c940e7-ee4b-4b77-9888-eb531127ef25",
   "metadata": {},
   "outputs": [],
   "source": [
    "explore.correlation_heatmap(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556b7398-84a9-44fd-a929-540caaf22653",
   "metadata": {},
   "source": [
    "## Correlation Heatmap Takeaways\n",
    "- There are no negative correlation in this dataset.\n",
    "- There does not appear to be any strong correlations with the current features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fd0643-74c7-497e-a3f2-f8810fa06ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = train.groupby('Team').sum()\n",
    "groups = groups[groups.medalist > 500].reset_index()\n",
    "groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981c5383-cd5d-46f5-a92a-3c05a5e6ede0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(10, 10))\n",
    "# sns.barplot(x='Team', y='medalist', data=train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
